# Ch12. Distributed Database

* Distributed database management system \(DDBMS\): Governs storage and processing of logically related data over interconnected computer systems 
  * Data and processing functions are distributed among seversal sites 
* Centralized database management system 
  * Required that corporate data be stored in a single central site 
  * Data access provided through dumb terminals

Factors That Aided DDBMS to Cope With Technological Advancement 

* Acceptance of Internet as a platform for business 
* Mobile wireless revolution
* Usage of application as a service 
* Focus on mobile business intelligence

Desirability of Distributed DBMS Over Centralized DBMS

* Performance degradation 
* High costs 
* Reliability problems 
* Scalability problems 
* Organizational rigidity

Pros:

* Data are located near greatest demand site 
* Faster data access and processing 
* Growth facilitation 
* Improved communications 
* Reduced operating costs 
* User-friendly interface 
* Less danger of a single point failure 
* Processor independence

Cons:

* Complexity of management and control 
* Technological difficulty 
* Security 
* Lack of standards 
* Increased storage and infrastructure requirements 
* Increased training cost
* Costs incurred due to the requirement of duplicated infrastructure

### Distributed Processing and Distributed Databases

* n distributed processing, a database’s logical processing is shared among two or more physically independent sites that are connected through a network
* Distributed database: Stores logically related database over two or more physically independent sites via computer network
  * Database fragments: Database composed of many parts in distributed database system

### Characteristics of Distributed Database Management Systems

* Application interface to interact with the end user, application programs, and other DBMSs within the distributed database 
* Validation to analyze data requests for syntax correctness 
* Transformation to decompose complex requests into atomic data request components 
* Query optimization to find the best access strategy \(which database fragments must be accessed by the query, and how must data updates, if any, be synchronized?
* Mapping to determine the data location of local and remote fragments 
* I/O interface to read or write data from or to permanent local storage 
* Formatting to prepare the data for presentation to the end user or to an application program • Security to provide data privacy at both local and remote databases 
* Backup and recovery to ensure the availability and recoverability of the database in case of a failure • DB administration features for the database administrator 
* Concurrency control to manage simultaneous data access and to ensure data consistency across database fragments in the DDBMS 
* Transaction management to ensure that the data move from one consistent state to another; this activity includes the synchronization of local and remote transactions as well as transactions across multiple distributed segment

A fully distributed database management system must perform all of the functions of a centralized DBMS, as follows:

1.  Receive the request of an application or end user. 
2. 2. Validate, analyze, and decompose the request. The request might include mathematical and logical operations such as the following: Select all customers with a balance greater than $1,000. The request might require data from only a single table, or it might require access to several tables. 
3. 3. Map the request’s logical-to-physical data components. 
4. 4. Decompose the request into several disk I/O operations. 
5. 5. Search for, locate, read, and validate the data. 
6. 6. Ensure database consistency, security, and integrity. 
7. 7. Validate the data for the conditions, if any, specified by the request. 
8. 8. Present the selected data in the required format.

### DDBMS Component

The DDBMS must include at least the following components:

* Computer workstations or remote devices \(sites or nodes\) that form the network system. The distributed database system must be independent of the computer system hardware. 
* Network hardware and software components that reside in each workstation or device. The network components allow all sites to interact and exchange data. Because the components—computers, operating systems, network hardware, and so on—are likely to be supplied by different vendors, it is best to ensure that distributed database functions can be run on multiple platforms. 
* Communications media that carry the data from one node to another. The DDBMS must be communications media-independent; that is, it must be able to support several types of communications media. 
* The **transaction processor \(TP\)**, which is the software component found in each computer or device that **requests data**. The transaction processor receives and processes the application’s remote and local data requests. The TP is also known as the application processor \(AP\) or the transaction manager \(TM\). 
* The **data processor \(DP\)**, which is the software component residing on each computer or device that **stores and retrieves data located at the site**. The DP is also known as the data manager \(DM\). A data processor may even be a centralized DBMS.

### Levels of Data and Process Distribution

In the single-site processing, single-site data \(SPSD\) scenario, 

* all processing is done on a single host computer 
* all data are stored on the host computer’s local disk system. 
* Processing cannot be done on the end user’s side of the system. 
* DBMS is accessed by dumb terminal

Multiple-Site Processing, Single-Site Data \(MPSD\)

* Multiple processes run on different computers sharing a single data repository 
* Require network file server running conventional applications 
  * Accessed through LAN 
* Client/server architecture 
  * Reduces network traffic 
  * Processing is distributed 
  * Supports data at multiple sites

Multiple-Site Processing, Single-SiteData \(MPSD\)

* Fully distributed database management system
* Support multiple data processors and transaction processors at multiple sites 
* Depending on the level of support for various types of databases, DDBMSs are classified as either homogeneous or heterogeneous.
  * Homogeneous: Integrate multiple instances of same DBMS over a network 
  * Heterogeneous: Integrate different types of DBMSs , same model
  * Fully heterogeneous: Support different DBMSs, each supporting different data model

### **DDBMS restrictions**

* Remote access is provided on a read-only basis 
*  Restrictions on the number of remote tables that may be accessed in a single transaction
* Restrictions on the number of distinct databases that may be accessed 
* Restrictions on the database model that may be accessed

## Distributed concurrency control

#### Two-phase commit \("2PC"\) protocol

* Guarantees if a portion of a transaction operation cannot be committed, all changes made at the other sites will be undone 
* To maintain a consistent database state
* Requires that each DP’s transaction log entry be written before database fragment is updated 
* DO-UNDO-REDO protocol: Roll transactions back and forward with the help of the system’s transaction log entries
* Write-ahead protocol: Forces the log entry to be

  written to permanent storage before actual operation takes place

* Defines operations between **coordinator** and **subordinates** 
* Phases of implementation
  * Preparation 
  * the final COMMIT

## 2PC: another description

In the two phase commit protocol, as the name implies, there are two phases:

* phase 1: commit request phase, aka 'voting' phase: coordinator sends a 'commit or abort?' \(aka 'query to commit' or 'prepare to commit'\) message to each participating transaction node; each node responds \(votes\), with a 'can commit' \(aka 'ready'\) or 'need to abort' \(aka 'abort'\) message
* phase 2: commit phase, aka 'completion' phase:
  * if in phase 1, all nodes responded with 'can commit', the coordinator sends a 'commit' phase to each node; each node commits, and sends an acknowledgment to the coordinator
  * or, if in phase 1, any node responded with 'need to abort', the coordinator sends an 'abort' message to each node; each node aborts, and sends an acknowledgment to the coordinator

The devil's in the details - all sorts of variations/refinements exist in implementations, but the above is the overall \(simple, robust\) idea.

It's an **all-or-nothing scheme** - either all nodes of a distributed transaction locally commit \(in which case the overall transaction is successful\), or all of them locally abort so that the DB is not left in an inconsistent state unlike in the 'Problem!' slide \(in which case the overall transaction fails and needs to be redone\).

## Distribution transparency

DDBMSs are designed to HIDE distribution specifics - this feature is called 'transparency', and can be classified into different kinds.

* Allows management of physically dispersed database as if centralized 
* Levels
  * Fragmentation transparency: end user does not know that the data is fragmented.
  * Location transparency: end user does not know where fragments are located.
  * Location mapping transparency: end user does not know how fragments are mapped.
  * Distrib. transparency is supported via a distributed data dictionary \(DDD\) \[aka DDC\], which contains the distributed global schema which local TPs use to translate user requests for processing by DPs.

## Distributed DB design

* Data fragmentation 
  * How to partition database into fragments
* Data replication 
  * Which fragments to replicate 
* Data allocation 
  * Where to locate those fragments and replicas

#### Data Fragmentation

* Breaks single object into many segments 
* Information is stored in distributed data catalog \(DDC\) 
* Strategies 
  * Horizontal fragmentation: Division of a relation into subsets \(fragments\) of tuples \(rows\) 
  * Vertical fragmentation: Division of a relation into attribute \(column\) subsets 
  * Mixed fragmentation: Combination of horizontal and vertical strategies

#### Data Replication

* Data copies stored at multiple sites served by a computer network 
* Mutual consistency rule: Replicated data fragments should be identical 
* Styles of replication
  * Push replication 
  * Pull replication
* Helps restore lost data

#### Data Replication Scenarios

* Fully replicated database 
  * Stores multiple copies of each database fragment at multiple sites 
* Partially replicated database
  * Stores multiple copies of some database fragments at multiple sites 
* Unreplicated database 
  * Stores each database fragment at a single site

#### Data Allocation Strategies

* Centralized data allocation
  * Entire database stored at one site
* Partitioned data allocation
  * Database is divided into two or more disjoined fragments and stored at two or more sites
* Replicated data allocation
  * Copies of one or more database fragments are stored at several sites

#### The CAP Theorem

CAP stands for:

* Consistency
* Availability 
* Partition tolerance
* Basically available, soft state, eventually consistent \(BASE\)
* Data changes are not immediate but propagate slowly through the system until all replicas are consistent



